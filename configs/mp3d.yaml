# dataset
dataset: "mp3d"

data_path: "data/v1/scans"
pretrained_model_path: "checkpoints/Latte/"
text_encoder: "google/flan-t5-base"
vae: "stabilityai/sd-vae-ft-ema"

# save and load
results_dir: "./results"
pretrained: 

# model config: 
model: LaHT-B/2
num_frames: 8
image_size: 256 # choices=[256, 512]
patch_size: 2
num_layer: 16
num_attention_heads: 16
attention_head_dim: 72
cross_attention_dim: 1152
camera_dim: 768
caption_channels: 768
num_sampling_steps: 1000
frame_interval: 3
mask_prob: 0.8
fixed_spatial: False
attention_bias: True
align_camera: False
align_text: False
learn_sigma: False
extras: 78 # [1, 2] 1 unconditional generation, 2 class-conditional generation

# datasets
datasets:
  - type: EScanDataset
    data_path: data/embodiedscan
    num_frames: 8
    sample_interval: 2
    image_size: 256
    mask_prefix: 3
    escan_ann_file: data/embodiedscan/embodiedscan_infos_train.pkl
    escan_vg_file: data/embodiedscan/embodiedscan_train_vg_all.json
    param:
      random: True
  - type: MP3DDataset
    data_path: data/v1/scans
    num_frames: 8
    image_size: 256
    mask_prob: 0.7
    param:
      random: True
  - type: VLNCEDataset
    data_path: data/vlnce/processed_rxr
    num_frames: 8
    image_size: 256
    mask_prob: 0.5
    param:
      random: True
  - type: VLNCEDataset
    data_path: data/vlnce/processed_r2r
    num_frames: 8
    image_size: 256
    mask_prob: 0.5
    param:
      random: True
# train config:
save_ceph: True # important
learning_rate: 1e-4
ckpt_every: 10000
clip_max_norm: 0.1
start_clip_iter: 20000
local_batch_size: 2 # important
max_train_steps: 1000000
global_seed: 3407
num_workers: 8
log_every: 50
lr_warmup_steps: 0
resume_from_checkpoint:
gradient_accumulation_steps: 1 # TODO
num_classes:

# low VRAM and speed up training
use_compile: False
mixed_precision: False
enable_xformers_memory_efficient_attention: True
gradient_checkpointing: True